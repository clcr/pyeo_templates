{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.ensemble as ens\n",
    "import gdal\n",
    "from osgeo import ogr, osr,gdal\n",
    "import os,errno\n",
    "from tempfile import TemporaryDirectory\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "import csv\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matching_dataset(in_dataset, out_path,\n",
    "                            format=\"GTiff\", bands=1, datatype=None):\n",
    "    \"\"\"Creates an empty gdal dataset with the same dimensions, projection and geotransform. Defaults to 1 band.\n",
    "    Datatype is set from the first layer of in_dataset if unspecified\"\"\"\n",
    "    driver = gdal.GetDriverByName(format)\n",
    "    if datatype is None:\n",
    "        datatype = in_dataset.GetRasterBand(1).DataType\n",
    "    out_dataset = driver.Create(out_path,\n",
    "                                xsize=in_dataset.RasterXSize,\n",
    "                                ysize=in_dataset.RasterYSize,\n",
    "                                bands=bands,\n",
    "                                eType=datatype)\n",
    "    out_dataset.SetGeoTransform(in_dataset.GetGeoTransform())\n",
    "    out_dataset.SetProjection(in_dataset.GetProjection())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_raster_for_ml(image_array):\n",
    "    \"\"\"Reshapes an array from gdal order [band, y, x] to scikit order [x*y, band]\"\"\"\n",
    "    bands, y, x = image_array.shape\n",
    "    image_array = np.transpose(image_array, (1, 2, 0))\n",
    "    image_array = np.reshape(image_array, (x * y, bands))\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(image_path, shape_path, attribute=\"CODE\", shape_projection_id=4326):\n",
    "    \"\"\"Given an image and a shapefile with categories, return x and y suitable\n",
    "    for feeding into random_forest.fit.\n",
    "    Note: THIS WILL FAIL IF YOU HAVE ANY CLASSES NUMBERED '0'\n",
    "    WRITE A TEST FOR THIS TOO; if this goes wrong, it'll go wrong quietly and in a way that'll cause the most issues\n",
    "     further on down the line.\"\"\"\n",
    "    with TemporaryDirectory() as td:\n",
    "        shape_projection = osr.SpatialReference()\n",
    "        shape_projection.ImportFromEPSG(shape_projection_id)\n",
    "        image = gdal.Open(image_path)\n",
    "        image_gt = image.GetGeoTransform()\n",
    "        x_res, y_res = image_gt[1], image_gt[5]\n",
    "        ras_path = os.path.join(td, \"poly_ras\")\n",
    "        ras_params = gdal.RasterizeOptions(\n",
    "            noData=0,\n",
    "            attribute=attribute,\n",
    "            xRes=x_res,\n",
    "            yRes=y_res,\n",
    "            outputType=gdal.GDT_Int16,\n",
    "            outputSRS=shape_projection\n",
    "        )\n",
    "        # This produces a rasterised geotiff that's right, but not perfectly aligned to pixels.\n",
    "        # This can probably be fixed.\n",
    "        gdal.Rasterize(ras_path, shape_path, options=ras_params)\n",
    "        rasterised_shapefile = gdal.Open(ras_path)\n",
    "        shape_array = rasterised_shapefile.GetVirtualMemArray()\n",
    "        local_x, local_y = get_local_top_left(image, rasterised_shapefile)\n",
    "        shape_sparse = sp.coo_matrix(shape_array)\n",
    "        y, x, features = sp.find(shape_sparse)\n",
    "        training_data = np.empty((len(features), image.RasterCount))\n",
    "        image_array = image.GetVirtualMemArray()\n",
    "        image_view = image_array[:,\n",
    "                     local_y: local_y + rasterised_shapefile.RasterYSize,\n",
    "                     local_x: local_x + rasterised_shapefile.RasterXSize\n",
    "                     ]\n",
    "        for index in range(len(features)):\n",
    "            training_data[index, :] = image_view[:, y[index], x[index]]\n",
    "    return training_data, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_top_left(raster1, raster2):\n",
    "    \"\"\"Gets the top-left corner of raster1 in the array of raster 2; WRITE A TEST FOR THIS\"\"\"\n",
    "    inner_gt = raster2.GetGeoTransform()\n",
    "    return point_to_pixel_coordinates(raster1, [inner_gt[0], inner_gt[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_pixel_coordinates(raster, point, oob_fail=False):\n",
    "    \"\"\"Returns a tuple (x_pixel, y_pixel) in a georaster raster corresponding to the point.\n",
    "    Point can be an ogr point object, a wkt string or an x, y tuple or list. Assumes north-up non rotated.\n",
    "    Will floor() decimal output\"\"\"\n",
    "    # Equation is rearrangement of section on affinine geotransform in http://www.gdal.org/gdal_datamodel.html\n",
    "    if isinstance(point, str):\n",
    "        point = ogr.CreateGeometryFromWkt(point)\n",
    "        x_geo = point.GetX()\n",
    "        y_geo = point.GetY()\n",
    "    if isinstance(point, list) or isinstance(point, tuple):  # There is a more pythonic way to do this\n",
    "        x_geo = point[0]\n",
    "        y_geo = point[1]\n",
    "    if isinstance(point, ogr.Geometry):\n",
    "        x_geo = point.GetX()\n",
    "        y_geo = point.GetY()\n",
    "    gt = raster.GetGeoTransform()\n",
    "    x_pixel = int(np.floor((x_geo - floor_to_resolution(gt[0], gt[1])) / gt[1]))\n",
    "    y_pixel = int(np.floor((y_geo - floor_to_resolution(gt[3], gt[5] * -1)) / gt[5]))  # y resolution is -ve\n",
    "    return x_pixel, y_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_to_resolution(input, resolution):\n",
    "    \"\"\"Returns input rounded DOWN to the nearest multiple of resolution.\"\"\"\n",
    "    return input - (input % resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_ml_out_to_raster(classes, width, height):\n",
    "    \"\"\"Reshapes an output [x*y] to gdal order [y, x]\"\"\"\n",
    "    # TODO: Test this.\n",
    "    image_array = np.reshape(classes, (height, width))\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(in_image_path, model, out_image_path,num_chunks =10):\n",
    "    print(\"Classifying image\")\n",
    "    image = gdal.Open(in_image_path)\n",
    "    image_array = image.GetVirtualMemArray()\n",
    "    features_to_classify = reshape_raster_for_ml(image_array)\n",
    "    width = image.RasterXSize\n",
    "    height = image.RasterYSize\n",
    "    out_chunks = []\n",
    "    for i, chunk in enumerate(np.array_split(features_to_classify, num_chunks)):\n",
    "        print(\"Classifying {0}\".format(i))\n",
    "        chunk_copy = np.copy(chunk)\n",
    "        out_chunks.append(model.predict(chunk_copy))\n",
    "    out_classes = np.concatenate(out_chunks)\n",
    "    image = gdal.Open(in_image_path)\n",
    "    out_image = create_matching_dataset(image, out_image_path)\n",
    "    image_array = None\n",
    "    image = None\n",
    "    out_image_array = out_image.GetVirtualMemArray(eAccess=gdal.GA_Update)\n",
    "    out_image_array[...] = reshape_ml_out_to_raster(out_classes, width, height)\n",
    "    out_image_array = None\n",
    "    out_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    with open(filepath, \"wb\") as fp:\n",
    "        pickle.dump(model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath):\n",
    "    with open(filepath, \"rb\") as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_training(in_classes,out_csv, sumarise_type = 'count'):\n",
    "    df = pd.DataFrame(in_classes, columns = ['type'])\n",
    "    if sumarise_type == 'count':\n",
    "        training_summary = df.groupby(['type']).size()\n",
    "    elif sumarise_type == 'mean':\n",
    "        training_summary = df.groupby(['type']).mean()\n",
    "    elif sumarise_type == 'median':\n",
    "        training_summary = df.groupby(['type']).median\n",
    "    else:\n",
    "        print('Add more math func here, can only summarise in terms of count, mean or median now')\n",
    "    training_summary.to_csv(out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_rf(features,classes):\n",
    "    model = ens.ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=0.55, min_samples_leaf=2,\n",
    "    min_samples_split=16, n_estimators=100, n_jobs=-1, class_weight='balanced')\n",
    "    model.fit(features, classes)\n",
    "    scores = cross_val_score(model, features, classes, cv=cross_val_repeats)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getallinfo(g):\n",
    "    (x_min, pixel_width, rotation, y_max, rotation, pixel_height) = g.GetGeoTransform()\n",
    "    rows = g.RasterYSize\n",
    "    cols = g.RasterXSize\n",
    "    bands = g.RasterCount\n",
    "    x_max = (cols*pixel_width) + x_min\n",
    "    y_min = y_max + (rows*pixel_height)\n",
    "    return x_min, pixel_width, rotation, y_max, rotation, pixel_height, rows, cols, bands, x_max, y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipShp(input_raster,shpfile_path,output_fldr):\n",
    "    (x_min, pixel_width, rotation, y_max, rotation, pixel_height, rows, cols, bands, x_max, y_min) = getallinfo(input_raster)\n",
    "  \n",
    " #   print getallinfo(input_raster)\n",
    "    clipfile = os.path.join(output_fldr, 'outline_clip.shp' )\n",
    "    remove_exist(clipfile)\n",
    "    print ('The clipped shapefile to the extent of the raster, resultant shp is saved in ' + clipfile )\n",
    "    os.system('ogr2ogr -clipdst ' + str(x_min) + ' ' + str(y_min) + ' ' + str(x_max) + ' ' + str(y_max) + ' ' + clipfile + ' ' + shpfile_path)   \n",
    "    return clipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_exist(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
    "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
    "            raise # re-raise exception if a different error occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ratio(alldata, classnumber):\n",
    "    results = []\n",
    "    results.append(classnumber)    \n",
    "    newclass = [num for num in alldata if np.logical_or(num == classnumber, classnumber in num)]\n",
    "    results.append(len(newclass))\n",
    "    results.append(round(len(newclass)/len(alldata),6))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_classes(inRaster, shpdir, field_name='GRID_CODE', out_fldr=' ',nodata = 0):\n",
    "    s0data = gdal.Open(inRaster)\n",
    "    with open(os.path.join(out_fldr, os.path.basename(inRaster)[:-4] + '_' + \"validation.csv\"), 'w') as fs:\n",
    "        writer = csv.writer(fs)\n",
    "        writer.writerow(['validateClass', 'PredictedClass', 'number', 'ratio'])\n",
    "        inshp = shpdir\n",
    "        print('~validating ... ' + inshp)\n",
    "        clipfile = clipShp(s0data, inshp, out_fldr)# clip shp to the extent of the raster\n",
    "        print('rasterise the shapefile')\n",
    "        (x_min, pixel_width, rotation, y_max, rotation, pixel_height, rows, cols, bands, x_max, y_min) = getallinfo(\n",
    "            s0data)\n",
    "        clipd_shp_rst = os.path.join(out_fldr, 'groundata_raster.tif')\n",
    "        remove_exist(clipd_shp_rst)\n",
    "        os.system('gdal_rasterize -a_nodata 0 -a ' + field_name + ' -ot Float32 -l ' + os.path.basename(\n",
    "            clipfile[:-4]) + ' -te ' + str(x_min) + ' ' + str(y_min) + ' ' + str(x_max) + ' ' + str(\n",
    "            y_max) + ' -tR ' + str(pixel_width) + ' ' + str(-pixel_height) + ' ' + clipfile + ' ' + clipd_shp_rst)\n",
    "        r = gdal.Open(clipd_shp_rst)\n",
    "        shp_array1 = r.GetRasterBand(1).ReadAsArray()\n",
    "        for class_i in np.unique(shp_array1):\n",
    "            all_class = np.zeros(shp_array1.shape)\n",
    "            all_class[shp_array1 == class_i] = 1  # now the shp only have 0 and 1, 1 are where validating points are\n",
    "            bs_array = s0data.GetRasterBand(1).ReadAsArray()  # .astype(np.float)\n",
    "            new = all_class* bs_array\n",
    "            for i in np.unique(new):\n",
    "                if i == nodata:\n",
    "                    continue  # skip\n",
    "                else:\n",
    "                    stat = []\n",
    "                    stat.append(str(class_i))\n",
    "                    testclass = str(i)\n",
    "                    stat.append(testclass)\n",
    "                    num = len(new[new == i])\n",
    "                    stat.append(num)\n",
    "                    total_nonnum = len(new[new != 0.])\n",
    "                    ratio = round(float(num) / float(total_nonnum), 6)\n",
    "                    stat.append(ratio)\n",
    "                    writer.writerow(stat)\n",
    "                    print(stat)\n",
    "            writer.writerow([])\n",
    "    fs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
